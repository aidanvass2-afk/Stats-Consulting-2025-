nb_combined <- glm.nb(
  
  n_claims ~ 
    
    ns(age, 4) +
    
    ns(reported_mileage, 4) +
    
    gender + marital + employment + area +
    
    primary_usage + ncd_level + fuel +
    
    body_type + vehicle_power +
    
    age:gender +
    
    gender:marital +
    
    offset(log(exposure)),
  
  data = freq_full
  
)

AIC(nb_combined)

###############################################
## CLEAN TEST DATA EXACTLY LIKE TRAINING DATA
###############################################

# 1. Same factor variables
fac_vars <- c(
  "gender","marital","employment","area","primary_usage",
  "overnight_parking","security_device","ncd_level",
  "transmission","fuel","body_type"
)

# 2. Same predictor list
preds <- c(
  "age","years_licensed","gender","marital","employment",
  "area","primary_usage","overnight_parking","security_device",
  "ncd_level","transmission","fuel","body_type",
  "vehicle_power","vehicle_age","engine_cc",
  "vehicle_value","reported_mileage","num_drivers"
)

# 3. Convert factor variables to factors with SAME LEVELS as training
for (v in fac_vars) {
  if (v %in% names(policies_test)) {
    policies_test[[v]] <- factor(policies_test[[v]],
                                 levels = levels(freq_full[[v]]))  
  }
}

# 4. Build cleaned test dataset
freq_test <- policies_test %>%
  dplyr::select(n_claims, exposure, all_of(preds)) %>%
  na.omit()

###############################################
## freq_test is now CLEAN and matches training
###############################################
freq_test$pred_claims <- predict(nb_combined,
                                 newdata = freq_test,
                                 type = "response")












############################################################
## 3. BINARY TARGET FOR AUC / CONFUSION MATRIX
############################################################

# Claim occurred (1 or 0)
freq_test$claim_binary <- ifelse(freq_test$n_claims > 0, 1, 0)

# Probability of >=1 claim from Poisson/NegBin
freq_test$prob_claim <- 1 - exp(-freq_test$pred_claims)

############################################################
## 4. AUC
############################################################

library(pROC)
auc_result <- roc(freq_test$claim_binary, freq_test$prob_claim)
auc_result
cat("AUC =", auc(auc_result), "\n")

############################################################
## 5. CONFUSION MATRIX (choose threshold 0.5 or optimise)
############################################################

# You can choose threshold = 0.5 OR optimise using Youden's J
threshold <- 0.5

freq_test$pred_class <- ifelse(freq_test$prob_claim > threshold, 1, 0)

# Confusion matrix
conf_mat <- table(
  Actual = freq_test$claim_binary,
  Predicted = freq_test$pred_class
)
conf_mat

############################################################
## 6. METRICS FROM CONFUSION MATRIX
############################################################

TP <- conf_mat["1", "1"]
TN <- conf_mat["0", "0"]
FP <- conf_mat["0", "1"]
FN <- conf_mat["1", "0"]

accuracy  <- (TP + TN) / sum(conf_mat)
precision <- TP / (TP + FP)
recall    <- TP / (TP + FN)
f1        <- 2 * precision * recall / (precision + recall)

cat("Accuracy:", round(accuracy, 4), "\n")
cat("Precision:", round(precision, 4), "\n")
cat("Recall:", round(recall, 4), "\n")
cat("F1 Score:", round(f1, 4), "\n")




###############################################
## CALIBRATION ON TEST SET (freq_test)
###############################################

# 1. Overall calibration: observed vs expected claims
calib_overall <- aggregate(
  cbind(obs = n_claims, exp = pred_claims) ~ 1,
  data = freq_test,
  FUN = sum
)

calib_overall$ratio <- calib_overall$obs / calib_overall$exp
calib_overall
# ratio close to 1 = good overall calibration


# 2. Calibration by deciles of predicted frequency
freq_test$decile <- cut(
  freq_test$pred_claims,
  breaks = quantile(freq_test$pred_claims, probs = seq(0, 1, 0.1)),
  include.lowest = TRUE
)

calib_deciles <- aggregate(
  cbind(obs = n_claims, exp = pred_claims) ~ decile,
  data = freq_test,
  FUN = mean
)

calib_deciles

# (Optional) quick plot
plot(calib_deciles$exp, calib_deciles$obs,
     xlab = "Expected mean claims per policy",
     ylab = "Observed mean claims per policy",
     main = "Test-set calibration by decile")
abline(0, 1, lty = 2)



###############################################
## 1. DECILE LIFT CHART
###############################################

# Sort test set by predicted frequency
freq_test <- freq_test[order(freq_test$pred_claims, decreasing = TRUE), ]

# Create 10 equal-sized buckets
freq_test$lift_decile <- ntile(freq_test$pred_claims, 10)

# Aggregate observed claims by decile
lift_table <- freq_test %>%
  group_by(lift_decile) %>%
  summarise(
    obs = mean(n_claims),
    exp = mean(pred_claims)
  ) %>%
  arrange(lift_decile)

lift_table

# Plot lift
plot(lift_table$lift_decile, lift_table$obs,
     type = "b", pch = 19,
     xlab = "Decile (1 = highest risk)",
     ylab = "Observed mean claims",
     main = "Lift Chart")
lines(lift_table$lift_decile, lift_table$exp, col = "blue", lwd = 2)
legend("topright", legend = c("Observed", "Expected"),
       col = c("black", "blue"), lwd = c(1,2))


###############################################
## 2. GINI COEFFICIENT / LORENZ CURVE
###############################################

library(ineq)

# Lorenz curve
lorenz <- Lc(freq_test$pred_claims, freq_test$n_claims)

# Plot Lorenz curve
plot(lorenz,
     main = "Lorenz Curve (Claims Weighted by Predictions)",
     xlab = "Cumulative Share of Policies",
     ylab = "Cumulative Share of Claims")

# Gini
gini <- ineq(freq_test$pred_claims, type = "Gini", weights = freq_test$n_claims)
gini
cat("Gini Coefficient =", round(gini, 4), "\n")

gini_actual <- function(actual, pred) {
  
  # Order by predicted values
  ord <- order(pred, decreasing = TRUE)
  
  actual <- actual[ord]
  pred   <- pred[ord]
  
  # cumulative proportions
  cum_actual <- cumsum(actual) / sum(actual)
  cum_pop    <- seq_along(actual) / length(actual)
  
  # Gini = area between diag and Lorenz curve * 2
  gini_val <- sum((cum_actual - cum_pop)) / length(actual)
  return(2 * gini_val)
}

# Compute Gini for your model:
gini_score <- gini_actual(freq_test$n_claims, freq_test$pred_claims)

cat("Gini =", round(gini_score, 4), "\n")

###############################################
## 3. PREDICTIVE DEVIANCE ON TEST SET
###############################################

theta <- nb_combined$theta

test_loglik <- sum(dnbinom(
  freq_test$n_claims,
  mu = freq_test$pred_claims,
  size = theta,
  log = TRUE
))

test_deviance <- -2 * test_loglik

cat("Predictive Deviance (Test) =", round(test_deviance, 1), "\n")


###############################################
## 4. MODEL RELATIVITIES FOR PRICING
###############################################

coefs <- coef(nb_combined)

# Convert log-coefficients to multiplicative relativities
relativities <- exp(coefs)

relativities

